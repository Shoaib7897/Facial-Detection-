{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 88  52  58]\n",
      "  [ 80  44  50]\n",
      "  [ 84  48  54]\n",
      "  ...\n",
      "  [ 55  36  45]\n",
      "  [ 55  36  45]\n",
      "  [ 55  36  45]]\n",
      "\n",
      " [[ 87  51  57]\n",
      "  [ 81  45  51]\n",
      "  [ 86  50  56]\n",
      "  ...\n",
      "  [ 55  36  45]\n",
      "  [ 55  36  45]\n",
      "  [ 55  36  45]]\n",
      "\n",
      " [[ 86  50  56]\n",
      "  [ 82  46  52]\n",
      "  [ 89  53  59]\n",
      "  ...\n",
      "  [ 55  36  45]\n",
      "  [ 55  36  45]\n",
      "  [ 55  36  45]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 78 100 111]\n",
      "  [ 79 101 112]\n",
      "  [ 72  94 105]\n",
      "  ...\n",
      "  [ 57  69  87]\n",
      "  [ 57  69  87]\n",
      "  [ 60  72  90]]\n",
      "\n",
      " [[ 85 107 118]\n",
      "  [ 80 102 113]\n",
      "  [ 67  89 100]\n",
      "  ...\n",
      "  [ 59  71  89]\n",
      "  [ 58  70  88]\n",
      "  [ 61  73  91]]\n",
      "\n",
      " [[ 91 113 124]\n",
      "  [ 83 105 116]\n",
      "  [ 69  91 102]\n",
      "  ...\n",
      "  [ 62  74  92]\n",
      "  [ 61  73  91]\n",
      "  [ 63  75  93]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#imread() reads the image in the given format and returns a 2D array if the image is not colored , if colored it returns a 3D array (R,G,B) just like below\n",
    "filepath = 'C:\\\\Users\\\\sagitec\\\\Desktop\\\\Projects\\\\LearnITGirl\\\\SampleImages\\\\Sim&ria.jpeg'\n",
    "original_image = cv.imread(filepath)\n",
    "print(original_image)\n",
    "original_image.ndim #ndim is n dimensions of array so it tells us if array is 2D or 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cvtColor() helps us change from one color spaces to another . Color spaces are BGR ,Gray\n",
    "#cv.COLOR_BGR2GRAY is for BGR to Gray conversion that is why now a 2D array is stored in gray_image\n",
    "#ndim(Number Of Array Dimensions) is a numpy ndarray attribute\n",
    "gray_image = cv.cvtColor(original_image, cv.COLOR_BGR2GRAY)\n",
    "gray_image.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#haarcascade_frontalface_alt.xml is a pretrained classifier which is good for detecting frontal faces , it takes long time to train if dataset is large but gives better accuracy than other classifiers\n",
    "#To use this classifier we need to use CascadeClassifier method which takes as parameter the filename where the classifier is loaded\n",
    "path = ''C:\\\\Users\\\\sagitec\\\\Desktop\\\\Projects\\\\haarcascade_frontalface_alt.xml''\n",
    "face_cascade = cv.CascadeClassifier(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[102 376  21  21]\n",
      " [437 179 121 121]\n",
      " [576 209 124 124]\n",
      " [766 252  54  54]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This detectMultiScale detects faces in the objects\n",
    "Parameters of detectMultiScale are image , scaleFactor , minNeighbors , minSize , maxSize\n",
    "image contains the matrix of the image which is put as input for detection\n",
    "scaaleFactor : The model being used has a fixed size defined during training. This means that this size of face is detected in the image if it occurs. So by rescaling the input image, we can resize a larger face to a smaller one, making it detectable for the algorithm.\n",
    "Using a small step for resizing, for example 1.05 which means we reduce size by 5 %, we increase the chance of a matching size with the model for detection is found\n",
    "minNeighbors : Suppose there are 4 faces in the image and I set minNeighbors as 1 that means that if a rectangle has 1 or more neighbors it will be considered as a face . The higher this factor is set the lesser the detections will be but it will be more accurate\n",
    "This is actually to rule out false positives.\n",
    "minsize : Minimum possible object size that means that objects smaller than that are ignored.\n",
    "maxsize : Maximum possible object size which means that objects larger than that are ignored.\n",
    "\"\"\"\n",
    "detected_faces = face_cascade.detectMultiScale(gray_image)\n",
    "#Detected faces are returned as a list of rectangles\n",
    "print(detected_faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cv2.rectangle(img, pt1, pt2, color, thickness, lineType, shift)\n",
    "for (column, row, width, height) in detected_faces:\n",
    "    cv.rectangle(\n",
    "        original_image,\n",
    "        (column, row),\n",
    "        (column + width, row + height),\n",
    "        (0, 255, 0),\n",
    "        2\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function will display the image in a window and it receives as input the name of the window and the image we previously got with the imread function\n",
    "cv.imshow('Image', original_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#waitkey(ms) the number represents for how many milliseconds is the image going to be displayed and 0 is a special case which means forever until a key is pressed\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#closes any open window and de-allocates associated memory\n",
    "cv.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
